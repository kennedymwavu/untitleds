---
title: "Proposed Solutions"
author: "Mwavu Kennedy"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# read in the data:
athlete_data <- read.csv(
  file = "Sports Data CW 2021.csv", 
  header = TRUE
)

```

# Task 1

Test for normality of the data first; Use shapiro-wilk normality test.

- $H_0$: The data are normally distributed
- $H_1$: The data are not normally distributed


Shapiro-wilk normality test for male plasma ferretin concentration:

```{r}
male_normality <- with(athlete_data, shapiro.test(x = Ferr[Sex == "male"]))
male_normality$p.value
```

Shapiro-wilk normality test for female plasma ferretin concentration:

```{r}
female_normality <- with(athlete_data, shapiro.test(x = Ferr[Sex == "female"]))
female_normality$p.value

```

The p-values for both males and males are less than the significance level
0.05 implying that the distributions of the data are significantly
different from the normal distribution.

This implies we can't use the unpaired two-samples t-test. We'll instead
use the non-parametric unpaired two-samples wilcoxon test:

```{r}
ferritin_diff <- wilcox.test(
  formula = Ferr ~ Sex, data = athlete_data, exact = FALSE
)

ferritin_diff

```

Since the p-value is less than the significance level `alpha = 0.05`, we
can conclude that males' median plasma ferritin concentration is
significantly different from females' median plasma ferritin concentration
with a p-value of `r ferritin_diff$p.value`

\newpage

# Task 2

Randomly divide the dataset into two sets, training ($n1 = 141$) and
testing ($n2 = 61$):

```{r}
# training indices:
set.seed(91)
n1 <- sample(x = nrow(athlete_data), size = 141, replace = FALSE)

# training data:
training <- athlete_data[n1, ]

# testing data:
testing <- athlete_data[-n1, ]

```


## a) Equation of a regression model

```{r}
# all column names:
colnms <- colnames(training)

# predictor variables:
predictors <- colnms[!colnms %in% c("Sport", "Ferr")]

# Equation:
frmla <- reformulate(predictors, response = "Ferr")
frmla

```

## b) Fit the model

```{r}
full_model <- lm(formula = frmla, data = training)
summary(full_model)

```

The only significant predictors are:
- Sex 
- LBM 
- BMI

## Fit a model with only the significant predictors

```{r}
smaller_model <- lm(
  formula = Ferr ~ Sex + LBM + BMI, data = training
)
summary(smaller_model)

```

## Is a the full model better than the smaller model?

Compare the two models using anova test:

```{r}
comparison <- anova(smaller_model, full_model)
comparison
```

The p-value = $0.732$ is not sufficiently low (less than $0.05$)
implying that the complex model (`full_model`) is not significantly better
than the simpler model (`smaller_model`). We should favor the smaller
model. In other words, the full model is not better than the
smaller model.

## c) Check the linear regression assumptions for the model fitted in part (b)

### 1. Linearity of the data

The linearity assumption can be checked by inspecting the Residuals vs Fitted plot:

```{r}
plot(full_model, 1)
```

There is a pattern in the residual plot meaning we can't assume
a linear relationship between the predictors and outcome variable

### 2. Normality of residuals

The QQ plot of residuals can be used to visually check the normality
assumption. The normal probability plot of residuals should
approximately follow a straight line.

```{r}
plot(full_model, 2)
```

Most of the points do not fall approximately along the reference line,
so we can assume non-normality.

shapiro test for normality:

```{r}
shapiro.test(full_model$residuals)
```

The p-value is less than $0.05$, confirming that the residuals
are not normally distributed.

### 3. Homoscedasticity

The residuals are assumed to have a constant variance.

We'll use the scale-location plot to check the homogeneity of variance
of the residuals.
Horizontal line with equally spread points is a good indication of
homoscedasticity.

```{r}
plot(full_model, 3)
```

That is not the case in our example, where we have a
heteroscedasticity problem.

### 4. Residuals vs Leverage

Used to identify influential cases, that is extreme values
that might influence the regression results when included
or excluded from the analysis.

Outliers and high leverage points can be identified by inspecting the
Residuals vs Leverage plot:

```{r}
plot(full_model, 5)
```

From the plot, there are no outliers which exceed
3 standard deviations, which is good.

However, there are high leverage points ie. there are some
data points have a leverage statistic above $2 \frac{(p + 1)}{n} =
2 \frac{(9 + 1)}{141} = 0.141844$.

